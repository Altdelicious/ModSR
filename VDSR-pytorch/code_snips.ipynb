{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-branch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import numpy as np\n",
    "import PIL.Image as pil_image\n",
    "import os\n",
    "import copy\n",
    "from scipy.io import savemat\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "from dataset import TrainDataset, EvalDataset\n",
    "from datasets import SRDataset\n",
    "\n",
    "from models import VDSR, VDSR_mod\n",
    "from imresize import imresize\n",
    "from utils import convert_rgb_to_ycbcr, convert_ycbcr_to_rgb, calc_psnr, calc_ssim, AverageMeter, preprocess_kernels, GradLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-plastic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(out, gt):\n",
    "    \n",
    "    l1_loss = nn.L1Loss()(out, gt)\n",
    "    \n",
    "    Grad_Loss = GradLoss()\n",
    "    Grad_Loss = Grad_Loss.to(device)\n",
    "    grad_loss = Grad_Loss(out, gt)\n",
    "    \n",
    "    #sobel = Sobel()(hr_bicubic.detach())\n",
    "    #loss_map = 1 - torch.clamp(sobel, 0, 1)\n",
    "    #loss_interp = nn.L1Loss()(out * loss_map, hr_bicubic * loss_map)\n",
    "    \n",
    "    a, b = 1.0, 0.1\n",
    "    pixel_loss = a*l1_loss + b*grad_loss\n",
    "    \n",
    "    return pixel_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-usage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Training.\n",
    "    \"\"\"\n",
    "    global start_epoch, epoch, checkpoint\n",
    "\n",
    "    # Initialize model or load checkpoint\n",
    "    if checkpoint is None:\n",
    "        model = VDSR_mod()\n",
    "        state_dict = model.state_dict()\n",
    "\n",
    "        #pre-trained weights loaded in model\n",
    "\n",
    "        for n, p in torch.load(weights_file, map_location=lambda storage, loc: storage).items():\n",
    "            if n in state_dict.keys():\n",
    "                state_dict[n].copy_(p)\n",
    "                if ('block' not in n):\n",
    "                    state_dict[n].requires_grad = False\n",
    "        \n",
    "        # Initialize the optimizer\n",
    "        optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "\n",
    "    else:\n",
    "        checkpoint = torch.load(checkpoint)\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        model = checkpoint['model']\n",
    "        optimizer = checkpoint['optimizer']\n",
    "\n",
    "    # Move to default device\n",
    "    model = model.to(device)\n",
    "    miles = [20, 50, 80]\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=miles, gamma=0.5, last_epoch=-1, verbose=False)\n",
    "\n",
    "    # Custom dataloaders\n",
    "    train_dataset = TrainDataset(train_file, scale, crop_size, kernel_file)\n",
    "    train_loader = DataLoader(dataset=train_dataset,\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=False,\n",
    "                                  num_workers=num_workers,\n",
    "                                  pin_memory=True,\n",
    "                                  drop_last=True)\n",
    "\n",
    "    # Epochs\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        # One epoch's training\n",
    "        train(train_loader=train_loader,\n",
    "              model=model,\n",
    "              optimizer=optimizer,\n",
    "              epoch=epoch)\n",
    "\n",
    "        torch.save(model.state_dict(), os.path.join(outputs_dir, 'best.pth'))\n",
    "        #scheduler.step()\n",
    "        \n",
    "    return model\n",
    "        \n",
    "def train(train_loader, model, optimizer, epoch):\n",
    "    \"\"\"\n",
    "    One epoch's training.\n",
    "    :param train_loader: DataLoader for training data\n",
    "    :param model: model\n",
    "    :param criterion: content loss function\n",
    "    :param optimizer: optimizer\n",
    "    :param epoch: epoch number\n",
    "    \"\"\"\n",
    "    model.train()  # training mode enables batch normalization\n",
    "\n",
    "    batch_time = AverageMeter()  # forward prop. + back prop. time\n",
    "    data_time = AverageMeter()  # data loading time\n",
    "    losses = AverageMeter()  # loss\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # Batches\n",
    "    for i, (lr_imgs, hr_imgs) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - start)\n",
    "\n",
    "        # Move to default device\n",
    "        lr_imgs = lr_imgs.to(device)  # (batch_size (N), 3, 24, 24)\n",
    "        hr_imgs = hr_imgs.to(device)  # (batch_size (N), 3, 96, 96)\n",
    "\n",
    "        # Forward prop.\n",
    "        sr_imgs = model(lr_imgs)  # (N, 3, 96, 96), in [-1, 1]\n",
    "\n",
    "        # Loss\n",
    "        loss = loss_fn(sr_imgs, hr_imgs)  # scalar\n",
    "\n",
    "        # Backward prop.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip gradients, if necessary\n",
    "        if grad_clip is not None:\n",
    "            clip_gradient(optimizer, grad_clip)\n",
    "\n",
    "        # Update model\n",
    "        optimizer.step()\n",
    "\n",
    "        # Keep track of loss\n",
    "        losses.update(loss.item(), lr_imgs.size(0))\n",
    "\n",
    "        # Keep track of batch time\n",
    "        batch_time.update(time.time() - start)\n",
    "\n",
    "        # Reset start time\n",
    "        start = time.time()\n",
    "\n",
    "        # Print status\n",
    "        #if i % print_freq == 0:\n",
    "        #    print('Epoch: [{0}][{1}/{2}]----'\n",
    "        #          'Batch Time {batch_time.val:.3f} ({batch_time.avg:.3f})----'\n",
    "        #          'Data Time {data_time.val:.3f} ({data_time.avg:.3f})----'\n",
    "        #          'Loss {loss.val:.4f} ({loss.avg:.4f})'.format(epoch, i, len(train_loader),\n",
    "        #                                                           batch_time=batch_time,\n",
    "        #                                                            data_time=data_time, loss=losses))\n",
    "            \n",
    "    del lr_imgs, hr_imgs, sr_imgs  # free some memory since their histories may be stored\n",
    "    \n",
    "def evaluate_single(dataset_dir, image, model, output_dir, scale, Kernel, device):\n",
    "    hr_file = dataset_dir + '/{}'.format(image)\n",
    "    # = 'data/Set5/LR_noncubic/X2/{}x2.png'.format(image)\n",
    "    output_file = output_dir + '/{}_x2.png'.format(image[:-4])\n",
    "    \n",
    "    hr = pil_image.open(hr_file).convert('RGB')\n",
    "    hr = np.array(hr).astype(np.float32)\n",
    "    lr = imresize(hr, scale=1./scale, kernel=Kernel)\n",
    "    lr = imresize(lr, scale=scale, output_shape=hr.shape, kernel='cubic')    \n",
    "\n",
    "    ycbcr_lr = convert_rgb_to_ycbcr(lr)\n",
    "    \n",
    "    y_lr = ycbcr_lr[..., 0]\n",
    "    y_lr /= 255.\n",
    "    y_lr = torch.from_numpy(y_lr).to(device)\n",
    "    y_lr = y_lr.unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(y_lr.float()).clamp(0.0, 1.0)\n",
    "    \n",
    "    ycbcr_hr = convert_rgb_to_ycbcr(hr)\n",
    "    y_hr = ycbcr_hr[..., 0]\n",
    "    y_hr /= 255.\n",
    "    y_hr = torch.from_numpy(y_hr).to(device)\n",
    "    y_hr = y_hr.unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    psnr = calc_psnr(y_hr, preds)\n",
    "    psnr = psnr.cpu().numpy()\n",
    "    \n",
    "    preds = preds.mul(255.0).cpu().numpy().squeeze(0).squeeze(0)\n",
    "    y_hr = y_hr.mul(255.0).cpu().numpy().squeeze(0).squeeze(0)\n",
    "    ssim = calc_ssim(y_hr, preds, scale=2)\n",
    "    \n",
    "    #output = np.array([preds, ycbcr_lr[..., 1], ycbcr_lr[..., 2]]).transpose([1, 2, 0])\n",
    "    #output = np.clip(convert_ycbcr_to_rgb(output), 0.0, 255.0).astype(np.uint8)\n",
    "    #output = pil_image.fromarray(output)\n",
    "    #output.save(output_file)\n",
    "    #print(psnr, ssim)\n",
    "    \n",
    "    return (psnr, ssim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-ballet",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = 'Urban100'\n",
    "dataset_dir = '../../data/{}/HR'.format(dataset)\n",
    "weights_file = '../MAML-simple/aniso_5000.pth'\n",
    "outputs_dir = 'output/Set5_mod'\n",
    "scale = 2\n",
    "\n",
    "kernel_file = '../../data/Set5/LR_noncubic/non_cubic.mat'\n",
    "#kernel_file = 'cubic'\n",
    "\n",
    "# Learning parameters\n",
    "checkpoint = None  # path to model checkpoint, None if none\n",
    "batch_size = 1\n",
    "crop_size = 128\n",
    "start_epoch = 0  # start at this epoch\n",
    "epochs = 50\n",
    "num_workers = 8  # number of workers for loading data in the DataLoader\n",
    "print_freq = 50  # print training status once every __ batches\n",
    "lr = 1e-4\n",
    "grad_clip = None  # clip if gradients are exploding\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "#image = 'woman'\n",
    "images = os.listdir(dataset_dir)\n",
    "Kernel = preprocess_kernels(kernel_file, sf=scale)\n",
    "\n",
    "lst_psnr, lst_ssim = [], []\n",
    "\n",
    "if not os.path.exists(outputs_dir):\n",
    "    os.makedirs(outputs_dir)\n",
    "    \n",
    "for i in range(len(images)):\n",
    "    train_file = dataset_dir + '/{}'.format(images[i])\n",
    "    model = main()\n",
    "    \n",
    "    psnr, ssim = evaluate_single(dataset_dir, images[i], model, outputs_dir, scale, Kernel, device)\n",
    "    \n",
    "    lst_psnr.append(psnr)\n",
    "    lst_ssim.append(ssim)\n",
    "    print(i)\n",
    "    \n",
    "print('Done')\n",
    "print(torch.mean(torch.FloatTensor(lst_psnr)), torch.mean(torch.FloatTensor(lst_ssim)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-customs",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Testing VDSR/any model - complete set of images (not individuals) without FTuning on test images\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = VDSR().to(device)\n",
    "\n",
    "state_dict = model.state_dict()\n",
    "dataset = 'BSD100'\n",
    "method = 'og'\n",
    "\n",
    "dataset_dir = '../../data/{}/HR'.format(dataset)\n",
    "output_dir = 'output/{}_{}'.format(dataset, method)\n",
    "\n",
    "#weights_file = 'output/Set14_{}/best.pth'.format(method)\n",
    "#weights_file = 'output/{}_{}/best.pth'.format(dataset, method)\n",
    "weights_file = 'pretrained_models/vdsr_x2.pth'\n",
    "\n",
    "#kernel_file = '../../data/Set5/LR_noncubic/iso_1.mat'\n",
    "kernel_file = 'cubic'\n",
    "scale = 2\n",
    "\n",
    "#images = os.listdir(dataset_dir)\n",
    "images = sorted(os.listdir(dataset_dir))\n",
    "Kernel = preprocess_kernels(kernel_file, sf=scale)\n",
    "\n",
    "\n",
    "for n, p in torch.load(weights_file, map_location=lambda storage, loc: storage).items():\n",
    "    if n in state_dict.keys():\n",
    "        state_dict[n].copy_(p)\n",
    "    else:\n",
    "        raise KeyError(n)\n",
    "\n",
    "lst_psnr, lst_ssim = [], []\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "for i in range(len(images)):\n",
    "    print(i)\n",
    "    \n",
    "    psnr, ssim = evaluate_single(dataset_dir, images[i], model, output_dir, scale, Kernel, device)\n",
    "    \n",
    "    lst_psnr.append(psnr)\n",
    "    lst_ssim.append(ssim)\n",
    "    \n",
    "print('Done')\n",
    "print(np.mean(lst_psnr), np.mean(lst_ssim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-female",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-bibliography",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entire net meta-trained, only adapters FTuned on images (beta=1e-3, alpha=1e-6, 1e-4), trained on DIV2K, test\n",
    "# scenario is real-world (Lr:Lr-son)\n",
    "\n",
    "# Set5 (cubic)        - VDSR (x2)                 - 37.5549/0.9595\n",
    "# Set5 (noncubic)     - VDSR (x2)                 - 28.7537/0.8339\n",
    "\n",
    "\n",
    "# Set14 (cubic)       - VDSR (x2)                 - 32.9226/0.9133\n",
    "# Set14 (noncubic)    - VDSR (x2)                 - 26.4692/0.7440\n",
    "\n",
    "\n",
    "# Urban100 (cubic)    - VDSR (x2)                 - 30.3503/0.9155\n",
    "# Urban100 (noncubic) - VDSR (x2)                 - 23.2416/0.6723\n",
    "\n",
    "# Set5 (cubic)        - VDSR (x4)                 - 31.2365/0.8832\n",
    "# Set5 (noncubic)     - VDSR (x4)                 - 29.4586/0.8479\n",
    "\n",
    "\n",
    "# Set14 (cubic)       - VDSR (x4)                 - 27.7680/0.7694\n",
    "# Set14 (noncubic)    - VDSR (x4)                 - 26.2408/0.7229\n",
    "\n",
    "\n",
    "# Urban100 (cubic)    - VDSR (x4)                 - 24.3303/0.7189\n",
    "# Urban100 (noncubic) - VDSR (x4)                 - 23.1669/0.6638\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-underwear",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-cylinder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-funeral",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-finland",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-induction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-generic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-burden",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-packing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
